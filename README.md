## RNA State Inference with LSTMs

Devin Willmott, Dr. David Murrugarra, Dr. Qiang Ye

---

Required packages:
------
* glob2
* numpy
* theano
* keras

Instructions
------
1) Get training set: From [http://www.rna.ccbb.utexas.edu/DAT/3C/SBPI/index.php], download and unzip all of the 16S rRNA files in the nopct format.

2) Get test set: From [http://users-birc.au.dk/zs/SHAPEsimulations/], download the native test set .ct files (contained in the link named '.zip archive').

3) In processdata.py, point the paths near the end of the file (lines 148 and 156) to the directories that you put the training and test set sequences in, respectively.

4) Run `python processdata.py` to generate the arrays for the LSTM and .pkl files for the HMM. Comment out the last part of processdata.py if you're feeling impatient.

5) In rnn.py, point the filepaths (lines 53 and 78) to the .npy files generated by processdata.py.

6) In hmm.py, point the filepaths (lines 105 and 106) to the .pkl files generated by processdata.py.

---

Then you're all set; run the RNN with

```python rnn.py```

to run with our hyperparameters, or use the command line arguments to choose your own. For example, to train and test an RNN with a learning rate of 0.01 and a network with three hidden layers of sizes 300, 200, and 100, run

```python rnn.py --lr 0.01 --hiddensizes 300 200 100```

The HMM has two command line arguments: k, the order of the HMM, and the mode. There are three modes: 'train' trains and saves an HMM of order k, 'run' uses a saved HMM of order k to perform inference on the test set, and 'cycle' does train' and 'run' using all orders of HMM from 1 to k. So, to train an order 4 HMM, you run

```python hmm.py 4 train```

